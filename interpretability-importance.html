<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.1 Yorumlanabilirliğin Önemi | Yorumlanabilir Makine Öğrenmesi</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="3.1 Importance of Interpretability | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.1 Importance of Interpretability | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2022-03-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="interpretability.html"/>
<link rel="next" href="taxonomy-of-interpretability-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>

<style>

#cta-button-desktop:hover, #cta-button-device:hover {
  background-color:   #ffc266; 
  border-color:   #ffc266; 
  box-shadow: none;
}
#cta-button-desktop, #cta-button-device{
  color: white;
  background-color:  #ffa31a;
  text-shadow:1px 1px 0 #444;
  text-decoration: none;
  border: 2px solid  #ffa31a;
  border-radius: 10px;
  position: fixed;
  padding: 5px 10px;
  z-index: 10;
  }

#cta-button-device {
  box-shadow: 0px 10px 10px -5px rgba(194,180,190,1);
  display:none;
  right: 20px;
  bottom: 20px;
  font-size: 20px;
 }

#cta-button-desktop {
  box-shadow: 0px 20px 20px -10px rgba(194,180,190,1);
  display:display;
  padding: 8px 16px;
  right: 40px;
  bottom: 40px;
  font-size: 25px;
}

@media (max-width : 450px) {
  #cta-button-device {display:block;}
  #cta-button-desktop {display:none;}
}


</style>


<a id="cta-button-desktop" href="https://leanpub.com/interpretable-machine-learning" rel="noopener noreferrer" target="blank"> Buy Book </a>

<a id="cta-button-device" href="https://leanpub.com/interpretable-machine-learning" rel="noopener noreferrer" target="blank">Buy</a>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">
  <!--Interpretable machine learning-->
  Yorumlanabilir Makine Öğrenmesi
  </a></li>

<li class="divider"></li>
<li><a href="index.html#summary"><!--Summary-->Özet<span></span></a></li>
<li class="chapter" data-level="1" data-path="preface-by-the-author.html"><a href="preface-by-the-author.html"><i class="fa fa-check"></i><b>1</b>
  <!--Preface by the Author-->Yazarın Önsözü<span></span></a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b><!--Introduction--> Giriş<span></span></a><ul>
<li class="chapter" data-level="2.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>2.1</b>
  <!--Story Time-->Hikaye Vakti<span></span></a><ul>
<li><a href="storytime.html#lightning-never-strikes-twice"><!--Lightning Never Strikes Twice-->Yıldırım Aynı Yere İki Kez Düşmez<span></span></a></li>
<li><a href="storytime.html#trust-fall">Trust Fall<span></span></a></li>
<li><a href="storytime.html#fermis-paperclips">Fermi’s Paperclips<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>2.2</b>
  <!--What Is Machine Learning?--> Makine Öğrenmesi Nedir?<span></span></a></li>
<li class="chapter" data-level="2.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>2.3</b>
  <!--Terminology-->Terminoloji<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>3</b>
  <!--Interpretability-->Yorumlanabilirlik<span></span></a><ul>
<li class="chapter" data-level="3.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>3.1</b>
  <!--Importance of Interpretability--> Yorumlanabilirliğin Önemi<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="taxonomy-of-interpretability-methods.html"><a href="taxonomy-of-interpretability-methods.html"><i class="fa fa-check"></i><b>3.2</b>
  <!--Taxonomy of Interpretability Methods--> Yorumlama Metotlarının Sınıflandırılması<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>3.3</b>
  <!--Scope of Interpretability--> Yorumlanabilirliğin Kapsamı<span></span></a><ul>
<li class="chapter" data-level="3.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>3.3.1</b>
  <!--Algorithm Transparency--> Algoritmaların Şeffaflığı<span></span></a></li>
<li class="chapter" data-level="3.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>3.3.2</b>
  Global, Holistic Model Interpretability<span></span></a></li>
<li class="chapter" data-level="3.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>3.3.3</b>
  Global Model Interpretability on a Modular Level<span></span></a></li>
<li class="chapter" data-level="3.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>3.3.4</b>
  Local Interpretability for a Single Prediction<span></span></a></li>
<li class="chapter" data-level="3.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-predictions"><i class="fa fa-check"></i><b>3.3.5</b>
  Local Interpretability for a Group of Predictions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="evaluation-of-interpretability.html"><a href="evaluation-of-interpretability.html"><i class="fa fa-check"></i><b>3.4</b>
  <!--Evaluation of Interpretability--> Yorumlanabilirliğin Değerlendirilmesi<span></span></a></li>
<li class="chapter" data-level="3.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>3.5</b>
  <!--Properties of Explanations--> Açıklamaların Özellikleri<span></span></a></li>
<li class="chapter" data-level="3.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>3.6</b>
  <!--Human-friendly Explanations--> İnsan Dostu Açıklamalar<span></span></a><ul>
<li class="chapter" data-level="3.6.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>3.6.1</b>
  <!--What Is an Explanation?--> Açıklama Nedir?<span></span></a></li>
<li class="chapter" data-level="3.6.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>3.6.2</b>
  <!--What Is a Good Explanation?-->İyi Açıklama Nasıl Olur?<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>4</b><!--Datasets--> Veriler<span></span></a><ul>
<li class="chapter" data-level="4.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>4.1</b>
  <!--Bike Rentals (Regression)--> Bisiklet Kiralama (Regression)<span></span></a></li>
<li class="chapter" data-level="4.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>4.2</b>
  <!--YouTube Spam Comments (Text Classification)--> Youtube Spam Yorumlar (Metin Sınıflandırması)<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>4.3</b>
  <!--Risk Factors for Cervical Cancer (Classification)--> Rahim Ağzı Kanseri (Sınıflandırma)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>5</b> 
  <!--Interpretable Models-->Yorumlanabilir Modeller<span></span></a><ul>
<li class="chapter" data-level="5.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>5.1</b> 
  Linear Regression<span></span></a><ul>
<li class="chapter" data-level="5.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>5.1.1</b> 
  <!--Interpretation--> Yorumlama<span></span></a></li>
<li class="chapter" data-level="5.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>5.1.2</b>
  <!--Example--> Örnek<span></span></a></li>
<li class="chapter" data-level="5.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>5.1.3</b>
  <!--Visual Interpretation--> Görsel Yorumlama<span></span></a></li>
<li class="chapter" data-level="5.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>5.1.4</b>
  <!--Explain Individual Predictions-->Özel Tahminleri Açıklama<span></span></a></li>
<li class="chapter" data-level="5.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>5.1.5</b>
  <!--Encoding of Categorical Features--> Kategorik Özniteliklerin Şifrelenmesi<span></span></a></li>
<li class="chapter" data-level="5.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>5.1.6</b>
  <!--Do Linear Models Create Good Explanations?--> Lineer Modeller İyi Açıklamalar Meydana Getirir Mi?<span></span></a></li>
<li class="chapter" data-level="5.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>5.1.7</b> 
  <!--Sparse Linear Models--> Aralıklı Lineer Modeller<span></span></a></li>
<li class="chapter" data-level="5.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>5.1.8</b> 
  <!--Advantages--> Avantajlar<span></span></a></li>
<li class="chapter" data-level="5.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>5.1.9</b>
  <!--Disadvantages--> Dezavantajlar<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>5.2</b> Logistic Regression<span></span></a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic.html"><a href="logistic.html#what-is-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>5.2.1</b>
  <!--What is Wrong with Linear Regression for Classification?--> Linear Regression ile Sınıflandırmanın Problemi Ne?<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="logistic.html"><a href="logistic.html#theory"><i class="fa fa-check"></i><b>5.2.2</b>
  <!--Theory--> Teori<span></span></a></li>
<li class="chapter" data-level="5.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>5.2.3</b>
  <!--Interpretation--> Yorumlama<span></span></a></li>
<li class="chapter" data-level="5.2.4" data-path="logistic.html"><a href="logistic.html#example-1"><i class="fa fa-check"></i><b>5.2.4</b>
  <!--Example--> Örnek<span></span></a></li>
<li class="chapter" data-level="5.2.5" data-path="logistic.html"><a href="logistic.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>5.2.5</b>
  <!--Advantages and Disadvantages--> Avantajlar ve Dezavantajlar<span></span></a></li>
<li class="chapter" data-level="5.2.6" data-path="logistic.html"><a href="logistic.html#software"><i class="fa fa-check"></i><b>5.2.6</b>
  <!--Software--> Yazılım<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>5.3</b> 
  <!--GLM, GAM and more-->GLM, GAM ve daha fazlası<span></span></a><ul>
<li class="chapter" data-level="5.3.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>5.3.1</b>
  <!--Non-Gaussian Outcomes - GLMs--> Non-Gaussian Sonuçlar - GLM'ler<span></span></a></li>
<li class="chapter" data-level="5.3.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>5.3.2</b>
  <!--Interactions--> Etkileşimler<span></span></a></li>
<li class="chapter" data-level="5.3.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>5.3.3</b>
  <!--Nonlinear Effects - GAMs--> Non-lineer etkiler - GAM'lar<span></span></a></li>
<li class="chapter" data-level="5.3.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>5.3.4</b>
  <!--Advantages--> Avantajlar<span></span></a></li>
<li class="chapter" data-level="5.3.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>5.3.5</b>
  <!--Disadvantages--> Dezavantajlar<span></span></a></li>
<li class="chapter" data-level="5.3.6" data-path="extend-lm.html"><a href="extend-lm.html#software-1"><i class="fa fa-check"></i><b>5.3.6</b>
  <!--Software--> Yazılım<span></span></a></li>
<li class="chapter" data-level="5.3.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>5.3.7</b>
  <!--Further Extensions--> İlaveler<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>5.4</b>
  <!--Decision Tree--> Karar Ağaçları<span></span></a><ul>
<li class="chapter" data-level="5.4.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>5.4.1</b>
  <!--Interpretation--> Yorumlama<span></span></a></li>
<li class="chapter" data-level="5.4.2" data-path="tree.html"><a href="tree.html#example-2"><i class="fa fa-check"></i><b>5.4.2</b>
  <!--Example--> Yorumlama<span></span></a></li>
<li class="chapter" data-level="5.4.3" data-path="tree.html"><a href="tree.html#advantages-2"><i class="fa fa-check"></i><b>5.4.3</b>
  <!--Advantages--> Avantajlar<span></span></a></li>
<li class="chapter" data-level="5.4.4" data-path="tree.html"><a href="tree.html#disadvantages-2"><i class="fa fa-check"></i><b>5.4.4</b>
  <!--Disadvantages--> Dezavantajlar<span></span></a></li>
<li class="chapter" data-level="5.4.5" data-path="tree.html"><a href="tree.html#software-2"><i class="fa fa-check"></i><b>5.4.5</b>
  <!--Software--> Yazılım<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>5.5</b>
  <!--Decision Rules--> Karar Kuralları<span></span></a><ul>
<li class="chapter" data-level="5.5.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>5.5.1</b>
  <!--Learn Rules from a Single Feature (OneR)--> Yalnızca Bir Öznitelikten Kural Öğrenme (OneR)<span></span></a></li>
<li class="chapter" data-level="5.5.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>5.5.2</b> Sequential Covering<span></span></a></li>
<li class="chapter" data-level="5.5.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>5.5.3</b> 
  <!--Bayesian Rule Lists-->Bayes-yan Kural Listeleri<span></span></a></li>
<li class="chapter" data-level="5.5.4" data-path="rules.html"><a href="rules.html#advantages-3"><i class="fa fa-check"></i><b>5.5.4</b>
  <!--Advantages--> Avantajlar<span></span></a></li>
<li class="chapter" data-level="5.5.5" data-path="rules.html"><a href="rules.html#disadvantages-3"><i class="fa fa-check"></i><b>5.5.5</b>
  <!--Disadvantages--> Dezavantajlar<span></span></a></li>
<li class="chapter" data-level="5.5.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>5.5.6</b>
  <!--Software and Alternatives--> Yazılım ve alternatifler<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>5.6</b> RuleFit<span></span></a><ul>
<li class="chapter" data-level="5.6.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>5.6.1</b>
  <!--Interpretation and Example--> Yorumlama ve Örnek<span></span></a></li>
<li class="chapter" data-level="5.6.2" data-path="rulefit.html"><a href="rulefit.html#theory-1"><i class="fa fa-check"></i><b>5.6.2</b>
  <!--Theory--> Teori<span></span></a></li>
<li class="chapter" data-level="5.6.3" data-path="rulefit.html"><a href="rulefit.html#advantages-4"><i class="fa fa-check"></i><b>5.6.3</b> 
  <!--Advantages-->Avantajlar<span></span></a></li>
<li class="chapter" data-level="5.6.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-4"><i class="fa fa-check"></i><b>5.6.4</b>
  <!--Disadvantages-->Dezavantajlar<span></span></a></li>
<li class="chapter" data-level="5.6.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>5.6.5</b>
  <!--Software and Alternative-->Yazıım ve alternatif<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>5.7</b>
  <!--Other Interpretable Models--> Diğer Yorumlanabilir Modeller<span></span></a><ul>
<li class="chapter" data-level="5.7.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>5.7.1</b>
  <!--Naive Bayes Classifier--> Naive Bayes ile Sınıflandırma<span></span></a></li>
<li class="chapter" data-level="5.7.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>5.7.2</b> K-Nearest Neighbors<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>6</b> 
  <!--Model-Agnostic Methods-->Modelden Bağımsız Metotlar<span></span></a></li>
<li class="chapter" data-level="7" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>7</b> 
  <!--Example-Based Explanations-->Örneklere Dayalı Açıklamalar<span></span></a></li>
<li class="chapter" data-level="8" data-path="global-methods.html"><a href="global-methods.html"><i class="fa fa-check"></i><b>8</b> 
  <!--Global Model-Agnostic Methods-->Modelden Bağımsız Evrensel Metotlar<span></span></a><ul>
<li class="chapter" data-level="8.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>8.1</b> 
  <!--Partial Dependence Plot (PDP)-->Kısmi Bağımlılık Grafiği (PDP)<span></span></a><ul>
<li class="chapter" data-level="8.1.1" data-path="pdp.html"><a href="pdp.html#pdp-based-feature-importance"><i class="fa fa-check"></i><b>8.1.1</b> 
  <!--PDP-based Feature Importance-->PDP Tabanlı Nitelik Değerleri<span></span></a></li>
<li class="chapter" data-level="8.1.2" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>8.1.2</b> Examples<span></span></a></li>
<li class="chapter" data-level="8.1.3" data-path="pdp.html"><a href="pdp.html#advantages-5"><i class="fa fa-check"></i><b>8.1.3</b> Advantages<span></span></a></li>
<li class="chapter" data-level="8.1.4" data-path="pdp.html"><a href="pdp.html#disadvantages-5"><i class="fa fa-check"></i><b>8.1.4</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="8.1.5" data-path="pdp.html"><a href="pdp.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>8.1.5</b> Software and Alternatives<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>8.2</b> Accumulated Local Effects (ALE) Plot<span></span></a><ul>
<li class="chapter" data-level="8.2.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>8.2.1</b> Motivation and Intuition<span></span></a></li>
<li class="chapter" data-level="8.2.2" data-path="ale.html"><a href="ale.html#theory-2"><i class="fa fa-check"></i><b>8.2.2</b> Theory<span></span></a></li>
<li class="chapter" data-level="8.2.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>8.2.3</b> Estimation<span></span></a></li>
<li class="chapter" data-level="8.2.4" data-path="ale.html"><a href="ale.html#examples-1"><i class="fa fa-check"></i><b>8.2.4</b> Examples<span></span></a></li>
<li class="chapter" data-level="8.2.5" data-path="ale.html"><a href="ale.html#advantages-6"><i class="fa fa-check"></i><b>8.2.5</b> Advantages<span></span></a></li>
<li class="chapter" data-level="8.2.6" data-path="ale.html"><a href="ale.html#disadvantages-6"><i class="fa fa-check"></i><b>8.2.6</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="8.2.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>8.2.7</b> Implementation and Alternatives<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>8.3</b> Feature Interaction<span></span></a><ul>
<li class="chapter" data-level="8.3.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>8.3.1</b> Feature Interaction?<span></span></a></li>
<li class="chapter" data-level="8.3.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>8.3.2</b> Theory: Friedman’s H-statistic<span></span></a></li>
<li class="chapter" data-level="8.3.3" data-path="interaction.html"><a href="interaction.html#examples-2"><i class="fa fa-check"></i><b>8.3.3</b> Examples<span></span></a></li>
<li class="chapter" data-level="8.3.4" data-path="interaction.html"><a href="interaction.html#advantages-7"><i class="fa fa-check"></i><b>8.3.4</b> Advantages<span></span></a></li>
<li class="chapter" data-level="8.3.5" data-path="interaction.html"><a href="interaction.html#disadvantages-7"><i class="fa fa-check"></i><b>8.3.5</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="8.3.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>8.3.6</b> Implementations<span></span></a></li>
<li class="chapter" data-level="8.3.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>8.3.7</b> Alternatives<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="decomposition.html"><a href="decomposition.html"><i class="fa fa-check"></i><b>8.4</b> Functional Decompositon<span></span></a><ul>
<li class="chapter" data-level="8.4.1" data-path="decomposition.html"><a href="decomposition.html#how-not-to-compute-the-components-i"><i class="fa fa-check"></i><b>8.4.1</b> How not to Compute the Components I<span></span></a></li>
<li class="chapter" data-level="8.4.2" data-path="decomposition.html"><a href="decomposition.html#functional-decomposition"><i class="fa fa-check"></i><b>8.4.2</b> Functional Decomposition<span></span></a></li>
<li class="chapter" data-level="8.4.3" data-path="decomposition.html"><a href="decomposition.html#how-not-to-compute-the-components-ii"><i class="fa fa-check"></i><b>8.4.3</b> How not to Compute the Components II<span></span></a></li>
<li class="chapter" data-level="8.4.4" data-path="decomposition.html"><a href="decomposition.html#functional-anova"><i class="fa fa-check"></i><b>8.4.4</b> Functional ANOVA<span></span></a></li>
<li class="chapter" data-level="8.4.5" data-path="decomposition.html"><a href="decomposition.html#generalized-functional-anova-for-dependent-features"><i class="fa fa-check"></i><b>8.4.5</b> Generalized Functional ANOVA for Dependent Features<span></span></a></li>
<li class="chapter" data-level="8.4.6" data-path="decomposition.html"><a href="decomposition.html#accumulated-local-effect-plots"><i class="fa fa-check"></i><b>8.4.6</b> Accumulated Local Effect Plots<span></span></a></li>
<li class="chapter" data-level="8.4.7" data-path="decomposition.html"><a href="decomposition.html#statistical-regression-models"><i class="fa fa-check"></i><b>8.4.7</b> Statistical Regression Models<span></span></a></li>
<li class="chapter" data-level="8.4.8" data-path="decomposition.html"><a href="decomposition.html#bonus-partial-dependence-plot"><i class="fa fa-check"></i><b>8.4.8</b> Bonus: Partial Dependence Plot<span></span></a></li>
<li class="chapter" data-level="8.4.9" data-path="decomposition.html"><a href="decomposition.html#advantages-8"><i class="fa fa-check"></i><b>8.4.9</b> Advantages<span></span></a></li>
<li class="chapter" data-level="8.4.10" data-path="decomposition.html"><a href="decomposition.html#disadvantages-8"><i class="fa fa-check"></i><b>8.4.10</b> Disadvantages<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>8.5</b> Permutation Feature Importance<span></span></a><ul>
<li class="chapter" data-level="8.5.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-3"><i class="fa fa-check"></i><b>8.5.1</b> Theory<span></span></a></li>
<li class="chapter" data-level="8.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>8.5.2</b> Should I Compute Importance on Training or Test Data?<span></span></a></li>
<li class="chapter" data-level="8.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>8.5.3</b> Example and Interpretation<span></span></a></li>
<li class="chapter" data-level="8.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-9"><i class="fa fa-check"></i><b>8.5.4</b> Advantages<span></span></a></li>
<li class="chapter" data-level="8.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-9"><i class="fa fa-check"></i><b>8.5.5</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="8.5.6" data-path="feature-importance.html"><a href="feature-importance.html#alternatives-1"><i class="fa fa-check"></i><b>8.5.6</b> Alternatives<span></span></a></li>
<li class="chapter" data-level="8.5.7" data-path="feature-importance.html"><a href="feature-importance.html#software-3"><i class="fa fa-check"></i><b>8.5.7</b> Software<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>8.6</b> Global Surrogate<span></span></a><ul>
<li class="chapter" data-level="8.6.1" data-path="global.html"><a href="global.html#theory-4"><i class="fa fa-check"></i><b>8.6.1</b> Theory<span></span></a></li>
<li class="chapter" data-level="8.6.2" data-path="global.html"><a href="global.html#example-3"><i class="fa fa-check"></i><b>8.6.2</b> Example<span></span></a></li>
<li class="chapter" data-level="8.6.3" data-path="global.html"><a href="global.html#advantages-10"><i class="fa fa-check"></i><b>8.6.3</b> Advantages<span></span></a></li>
<li class="chapter" data-level="8.6.4" data-path="global.html"><a href="global.html#disadvantages-10"><i class="fa fa-check"></i><b>8.6.4</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="8.6.5" data-path="global.html"><a href="global.html#software-4"><i class="fa fa-check"></i><b>8.6.5</b> Software<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>8.7</b> Prototypes and Criticisms<span></span></a><ul>
<li class="chapter" data-level="8.7.1" data-path="proto.html"><a href="proto.html#theory-5"><i class="fa fa-check"></i><b>8.7.1</b> Theory<span></span></a></li>
<li class="chapter" data-level="8.7.2" data-path="proto.html"><a href="proto.html#examples-3"><i class="fa fa-check"></i><b>8.7.2</b> Examples<span></span></a></li>
<li class="chapter" data-level="8.7.3" data-path="proto.html"><a href="proto.html#advantages-11"><i class="fa fa-check"></i><b>8.7.3</b> Advantages<span></span></a></li>
<li class="chapter" data-level="8.7.4" data-path="proto.html"><a href="proto.html#disadvantages-11"><i class="fa fa-check"></i><b>8.7.4</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="8.7.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>8.7.5</b> Code and Alternatives<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="local-methods.html"><a href="local-methods.html"><i class="fa fa-check"></i><b>9</b> 
  <!--Local Model-Agnostic Methods-->Modelden Bağımsız Yerel Metotlar<span></span></a><ul>
<li class="chapter" data-level="9.1" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>9.1</b> Individual Conditional Expectation (ICE)<span></span></a><ul>
<li class="chapter" data-level="9.1.1" data-path="ice.html"><a href="ice.html#examples-4"><i class="fa fa-check"></i><b>9.1.1</b> Examples<span></span></a></li>
<li class="chapter" data-level="9.1.2" data-path="ice.html"><a href="ice.html#advantages-12"><i class="fa fa-check"></i><b>9.1.2</b> Advantages<span></span></a></li>
<li class="chapter" data-level="9.1.3" data-path="ice.html"><a href="ice.html#disadvantages-12"><i class="fa fa-check"></i><b>9.1.3</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="9.1.4" data-path="ice.html"><a href="ice.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>9.1.4</b> Software and Alternatives<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>9.2</b> Local Surrogate (LIME)<span></span></a><ul>
<li class="chapter" data-level="9.2.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>9.2.1</b> LIME for Tabular Data<span></span></a></li>
<li class="chapter" data-level="9.2.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>9.2.2</b> LIME for Text<span></span></a></li>
<li class="chapter" data-level="9.2.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>9.2.3</b> LIME for Images<span></span></a></li>
<li class="chapter" data-level="9.2.4" data-path="lime.html"><a href="lime.html#advantages-13"><i class="fa fa-check"></i><b>9.2.4</b> Advantages<span></span></a></li>
<li class="chapter" data-level="9.2.5" data-path="lime.html"><a href="lime.html#disadvantages-13"><i class="fa fa-check"></i><b>9.2.5</b> Disadvantages<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>9.3</b> Counterfactual Explanations<span></span></a><ul>
<li class="chapter" data-level="9.3.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>9.3.1</b> Generating Counterfactual Explanations<span></span></a></li>
<li class="chapter" data-level="9.3.2" data-path="counterfactual.html"><a href="counterfactual.html#example-8"><i class="fa fa-check"></i><b>9.3.2</b> Example<span></span></a></li>
<li class="chapter" data-level="9.3.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-14"><i class="fa fa-check"></i><b>9.3.3</b> Advantages<span></span></a></li>
<li class="chapter" data-level="9.3.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-14"><i class="fa fa-check"></i><b>9.3.4</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="9.3.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>9.3.5</b> Software and Alternatives<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>9.4</b> Scoped Rules (Anchors)<span></span></a><ul>
<li class="chapter" data-level="9.4.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>9.4.1</b> Finding Anchors<span></span></a></li>
<li class="chapter" data-level="9.4.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>9.4.2</b> Complexity and Runtime<span></span></a></li>
<li class="chapter" data-level="9.4.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>9.4.3</b> Tabular Data Example<span></span></a></li>
<li class="chapter" data-level="9.4.4" data-path="anchors.html"><a href="anchors.html#advantages-15"><i class="fa fa-check"></i><b>9.4.4</b> Advantages<span></span></a></li>
<li class="chapter" data-level="9.4.5" data-path="anchors.html"><a href="anchors.html#disadvantages-15"><i class="fa fa-check"></i><b>9.4.5</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="9.4.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>9.4.6</b> Software and Alternatives<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9.5</b> Shapley Values<span></span></a><ul>
<li class="chapter" data-level="9.5.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>9.5.1</b> General Idea<span></span></a></li>
<li class="chapter" data-level="9.5.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>9.5.2</b> Examples and Interpretation<span></span></a></li>
<li class="chapter" data-level="9.5.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>9.5.3</b> The Shapley Value in Detail<span></span></a></li>
<li class="chapter" data-level="9.5.4" data-path="shapley.html"><a href="shapley.html#advantages-16"><i class="fa fa-check"></i><b>9.5.4</b> Advantages<span></span></a></li>
<li class="chapter" data-level="9.5.5" data-path="shapley.html"><a href="shapley.html#disadvantages-16"><i class="fa fa-check"></i><b>9.5.5</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="9.5.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>9.5.6</b> Software and Alternatives<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>9.6</b> SHAP (SHapley Additive exPlanations)<span></span></a><ul>
<li class="chapter" data-level="9.6.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>9.6.1</b> Definition<span></span></a></li>
<li class="chapter" data-level="9.6.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>9.6.2</b> KernelSHAP<span></span></a></li>
<li class="chapter" data-level="9.6.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>9.6.3</b> TreeSHAP<span></span></a></li>
<li class="chapter" data-level="9.6.4" data-path="shap.html"><a href="shap.html#examples-5"><i class="fa fa-check"></i><b>9.6.4</b> Examples<span></span></a></li>
<li class="chapter" data-level="9.6.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>9.6.5</b> SHAP Feature Importance<span></span></a></li>
<li class="chapter" data-level="9.6.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>9.6.6</b> SHAP Summary Plot<span></span></a></li>
<li class="chapter" data-level="9.6.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>9.6.7</b> SHAP Dependence Plot<span></span></a></li>
<li class="chapter" data-level="9.6.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>9.6.8</b> SHAP Interaction Values<span></span></a></li>
<li class="chapter" data-level="9.6.9" data-path="shap.html"><a href="shap.html#clustering-shapley-values"><i class="fa fa-check"></i><b>9.6.9</b> Clustering Shapley Values<span></span></a></li>
<li class="chapter" data-level="9.6.10" data-path="shap.html"><a href="shap.html#advantages-17"><i class="fa fa-check"></i><b>9.6.10</b> Advantages<span></span></a></li>
<li class="chapter" data-level="9.6.11" data-path="shap.html"><a href="shap.html#disadvantages-17"><i class="fa fa-check"></i><b>9.6.11</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="9.6.12" data-path="shap.html"><a href="shap.html#software-5"><i class="fa fa-check"></i><b>9.6.12</b> Software<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>10</b> Neural Network Interpretation<span></span></a><ul>
<li class="chapter" data-level="10.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>10.1</b> Learned Features<span></span></a><ul>
<li class="chapter" data-level="10.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>10.1.1</b> Feature Visualization<span></span></a></li>
<li class="chapter" data-level="10.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>10.1.2</b> Network Dissection<span></span></a></li>
<li class="chapter" data-level="10.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-18"><i class="fa fa-check"></i><b>10.1.3</b> Advantages<span></span></a></li>
<li class="chapter" data-level="10.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-18"><i class="fa fa-check"></i><b>10.1.4</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="10.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>10.1.5</b> Software and Further Material<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html"><i class="fa fa-check"></i><b>10.2</b> Pixel Attribution (Saliency Maps)<span></span></a><ul>
<li class="chapter" data-level="10.2.1" data-path="pixel-attribution.html"><a href="pixel-attribution.html#vanilla-gradient-saliency-maps"><i class="fa fa-check"></i><b>10.2.1</b> Vanilla Gradient (Saliency Maps)<span></span></a></li>
<li class="chapter" data-level="10.2.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html#deconvnet"><i class="fa fa-check"></i><b>10.2.2</b> DeconvNet<span></span></a></li>
<li class="chapter" data-level="10.2.3" data-path="pixel-attribution.html"><a href="pixel-attribution.html#grad-cam"><i class="fa fa-check"></i><b>10.2.3</b> Grad-CAM<span></span></a></li>
<li class="chapter" data-level="10.2.4" data-path="pixel-attribution.html"><a href="pixel-attribution.html#guided-grad-cam"><i class="fa fa-check"></i><b>10.2.4</b> Guided Grad-CAM<span></span></a></li>
<li class="chapter" data-level="10.2.5" data-path="pixel-attribution.html"><a href="pixel-attribution.html#smoothgrad"><i class="fa fa-check"></i><b>10.2.5</b> SmoothGrad<span></span></a></li>
<li class="chapter" data-level="10.2.6" data-path="pixel-attribution.html"><a href="pixel-attribution.html#examples-6"><i class="fa fa-check"></i><b>10.2.6</b> Examples<span></span></a></li>
<li class="chapter" data-level="10.2.7" data-path="pixel-attribution.html"><a href="pixel-attribution.html#advantages-19"><i class="fa fa-check"></i><b>10.2.7</b> Advantages<span></span></a></li>
<li class="chapter" data-level="10.2.8" data-path="pixel-attribution.html"><a href="pixel-attribution.html#disadvantages-19"><i class="fa fa-check"></i><b>10.2.8</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="10.2.9" data-path="pixel-attribution.html"><a href="pixel-attribution.html#software-6"><i class="fa fa-check"></i><b>10.2.9</b> Software<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html"><i class="fa fa-check"></i><b>10.3</b> Detecting Concepts<span></span></a><ul>
<li class="chapter" data-level="10.3.1" data-path="detecting-concepts.html"><a href="detecting-concepts.html#tcav-testing-with-concept-activation-vectors"><i class="fa fa-check"></i><b>10.3.1</b> TCAV: Testing with Concept Activation Vectors<span></span></a></li>
<li class="chapter" data-level="10.3.2" data-path="detecting-concepts.html"><a href="detecting-concepts.html#example-9"><i class="fa fa-check"></i><b>10.3.2</b> Example<span></span></a></li>
<li class="chapter" data-level="10.3.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html#advantages-20"><i class="fa fa-check"></i><b>10.3.3</b> Advantages<span></span></a></li>
<li class="chapter" data-level="10.3.4" data-path="detecting-concepts.html"><a href="detecting-concepts.html#disadvantages-20"><i class="fa fa-check"></i><b>10.3.4</b> Disadvantages<span></span></a></li>
<li class="chapter" data-level="10.3.5" data-path="detecting-concepts.html"><a href="detecting-concepts.html#bonus-other-concept-based-approaches"><i class="fa fa-check"></i><b>10.3.5</b> Bonus: Other Concept-based Approaches<span></span></a></li>
<li class="chapter" data-level="10.3.6" data-path="detecting-concepts.html"><a href="detecting-concepts.html#software-7"><i class="fa fa-check"></i><b>10.3.6</b> Software<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>10.4</b> Adversarial Examples<span></span></a><ul>
<li class="chapter" data-level="10.4.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>10.4.1</b> Methods and Examples<span></span></a></li>
<li class="chapter" data-level="10.4.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>10.4.2</b> The Cybersecurity Perspective<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>10.5</b> Influential Instances<span></span></a><ul>
<li class="chapter" data-level="10.5.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>10.5.1</b> Deletion Diagnostics<span></span></a></li>
<li class="chapter" data-level="10.5.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>10.5.2</b> Influence Functions<span></span></a></li>
<li class="chapter" data-level="10.5.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>10.5.3</b> Advantages of Identifying Influential Instances<span></span></a></li>
<li class="chapter" data-level="10.5.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>10.5.4</b> Disadvantages of Identifying Influential Instances<span></span></a></li>
<li class="chapter" data-level="10.5.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-5"><i class="fa fa-check"></i><b>10.5.5</b> Software and Alternatives<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>11</b> A Look into the Crystal Ball<span></span></a><ul>
<li class="chapter" data-level="11.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>11.1</b> The Future of Machine Learning<span></span></a></li>
<li class="chapter" data-level="11.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>11.2</b> The Future of Interpretability<span></span></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>12</b> Contribute to the Book<span></span></a></li>
<li class="chapter" data-level="13" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>13</b> Citing this Book<span></span></a></li>
<li class="chapter" data-level="14" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>14</b> Translations<span></span></a></li>
<li class="chapter" data-level="15" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>15</b> Acknowledgements<span></span></a></li>
<li><a href="references.html#references">References<span></span></a><ul>
<li><a href="r-packages-used.html#r-packages-used">R Packages Used<span></span></a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li> 
<li><a href="https://christophmolnar.com/impressum/" target="_blank">Impressum</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interpretability-importance" class="section level2 hasAnchor">
<h2><span class="header-section-number">3.1</span> Yorumlanabilirliğin Önemi<a href="interpretability-importance.html#interpretability-importance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
  <p>Bir model iyi performans gösteriyorsa, neden ona <strong>güvenip</strong> aldığı kararların <strong>nedenini</strong>
    görmezden gelmiyoruz? "Problem şu ki, sınıflandırmanın doğruluğu gibi tek bir ölçüm aracı, gerçek dünyadaki çoğu
    problemi tümüyle açıklayamamakta." (Doshi-Velez ve Kim 2017 <a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>)
  </p>
  <p>
  Yorumlanabilirliğin neden önemli olduğunu daha derinden inceleyelim. Bir tahmin yapmak üzere model oluştururken, bir
    değiş-tokuş yapmanız gerekir: Sadece <strong>neyin</strong> tahmin edildiğini mi anlamaya çalışıyorsunuz? Örneğin 
    bir müşterinin vazgeçme olasılığını veya bir ilacın hastaya ne kadar iyi geleceğini tahmin etmek gibi. Yoksa, bir ihtimal
    modelin yorumlanabilir olması adına performanstan ödün vermek ve tahminlerin neden öyle yapıldıklarını öğrenmek
    mi istiyorsunuz? Bazı durumlarda kararların nasıl alındığı umrunuzda olmaz, modelin test verisindeki performansının
    iyi olması yeterlidir. Ama diğer durumlarda, "nedenleri" bilmek problem hakkında daha fazla şey öğrenmenize yardımcı
    olabilir. Bazı modeller düşük riskli ortamlarda çalıştırıldıklarından açıklanmaya ihtiyaç duymaz, yani böyle bir modelin
    yapacağı herhangi bir hatanın ciddi sonuçları yoktur (bir film tavsiye sisteminde olduğu gibi), ya da kullanılan metotun
    üstünde önceden genişçe bir çalışma yapılmış ve metot iyice değerlendirilmiştir (görsel karakter tanıma). Yorumlanabilirliğe
    olan ihtiyaç, problemlerin tanımlanmasındaki eksiklikten doğar (Doshi-Velez ve Kim 2017), yani belli problemler ve görevler
    için tahminler ("Ne?" sorusunun cevabı) tek başına yeterli değildir. Model aynı zamanda tahminleri nasıl yaptığını 
    ("Nasıl?" sorusunu) da açıklamalıdır, çünkü doğru tahminler elinizdeki problemin yalnızca bir kısmını çözer. Aşağıdaki
    sebepler yorumlanabilirliğe ve açıklamalara olan talebi güçlendirir (Doshi-Velez ve Kim 2017, Miller 2017).
  </p>
<p>
  <strong>İnsan merakı ve öğrenmek:</strong> İnsanlarda, çevrede beklenmedik durumlar oluştuğunda güncellenen zihinsel bir
  model vardır. Bu güncelleme beklenmedik duruma bir açıklama getirilerek olur. Örneğin, bir insan hasta olduğunda "Neden hasta
  hissediyorum?" diye sorar. O kırmızı üzümleri her yediğinde hasta olduğunu öğrenir. Zihnindeki modeli günceller ve 
  üzümlerin hastalığa sebep olduklarına, dolayısıyla onlardan uzak durulması gerektiğine karar verir. Araştırmalar sırasında
  iç mekanizmaları anlaşılmayan modeller kullanıldığında, eğer model açıklamadan tahminlerini sunuyorsa, bilimsel bulgular
  tümüyle gizli kalır. Yapılan tahminlerin niye yapıldığını, belli davranışların neden sergilendiğini öğrenmek
  ve merakı doyurmak için yorumlanabilirlik ve açıklamalar hayati önem taşır. Tabii ki insanlar olan her şeyin
  açıklamasına ihtiyaç duymaz. Çoğu insan için bilgisayarların nasıl çalıştığını anlamamak bir problem oluşturmaz.
  Beklenmedik olaylar bizi merakta bırakır, örneğin: Bilgisayarım niye durduk yere kapanıyor?
  </p>  
  <p>
  Dünyanın anlamını bulmak, öğrenmekle yakından ilişkilidir. Bildiklerimizdeki çelişkileri veya tutarsızlıkları çözüp
    uyumlu hale getirmeyi isteriz. Bir insan "Beni hiç ısırmayan köpeğim şimdi ne oldu da beni ısırdı?" diye sorabilir.
    Köpeğin geçmişteki davranışının bilgisiyle yeni tecrübe arasında bir çelişki vardır. Veterinerin açıklaması köpek
    sahibinin çelişik bilgilerini uzlaştırır: "Köpek strese girmiş." Bir makinenin kararları insan hayatını ne kadar
    etkilerse makinenin ortaya bir açıklama koyması o kadar önem kazanır. Makine öğrenmesi modeli bir kredi başvurusunu
    reddettiğinde bu başvuranlar için beklenmedik bir durum olabilir. Birbiriyle çelişen beklenti ve gerçekliği uzlaştırmak
    için bir açıklamaya ihtiyaç duyarlar. Açıklamaların durumu tümüyle açıklamaları gerekmez, ama ana sebebi göstermeleri gerekir.
    Bir diğer örnek ise algoritmik ürün tavsiyesidir. Şahsen ben belli ürünlerin ve filmlerin algoritmik olarak neden
    önerildiklerini merak etmişimdir. Genelde sebep barizdir: Reklamcılık beni internette takip eder ve bir çamaşır yıkama
    makinesi aldığımda, çamaşır yıkama makinesi reklamlarının beni takip etmeye başlayacağını bilirim. Sepetimde bir şapka
    varsa bana bir eldiven önermek gayet mantıklıdır. Algoritma bir filmi önerir çünkü beğendiğim filmleri beğenmiş kullanıcılar
    bu bana tavsiye edilen filmi de beğenmiştir. İnternet şirketleri zamanla artan bir şekilde yaptıkları tavsiyelere açıklamalar
    ekliyorlar. Buna iyi bir örnek sık satın alınmış ürün kombinasyonlarına dayanan ürün tavsiyeleri:
  </p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:amazon-recommendation"></span>
<img src="images/amazon-freq-bought-together.png" alt="Recommended products that are frequently bought together." width="\textwidth" />
<p class="caption">
ŞEKİL 3.1: Sıklıkla birlikte satın alınan ürünler tavsiye oluşturulurken değerlendirilir.
</p>
</div>
  <p>Birçok bilimsel alanda niceliksel metotlardan niteliksel metotlara (sosyoloji, psikoloji) ve makine öğrenmesine (biyoloji
    gen bilimi) doğru bir değişim var. <strong>Bilimin amacı</strong> bilgi elde etmektir ama çoğu problem büyük veri setleriyle ve
  kara kutu modellerle çözülür. Veri yerine modelin kendisi bilginin kaynağı haline gelir. Yorumlanabilirlik model
    tarafından yakalanan bu ek bilgiyi ortaya çıkarmayı mümkün kılar.
  </p>
  <p>
  Makine öğrenmesi modelleri güvenlik önlemleri ve test gerektiren gerçek görevleri üstlenir. Kendi kendine sürüş
    sistemine sahip bir arabanın derin öğrenmeyle bisikletçileri tespit ettiğini hayal edin. Sistemin yaptığı
    soyutlamanın hatasız olduğundan %100 emin olmak istersiniz, çünkü bisikletçilerin üstüne sürmek oldukça kötüdür.
    Bir açıklama öğrenilmiş en önemli özelliğin bisikletin tekerleklerini tanımak olduğunu ortaya çıkarabilir, ve bu 
    açıklama yanlarında tekerlekleri kısmen kapatan çantalar olan bisikletler gibi uç durumlar hakkında düşünebilmeyi sağlar.
  </p>
  <p>
  Her durumda modeller eğitim verisindeki ön yargıları içermek zorundadır. Bu durum modellerinizi, yeterince temsil edilmemiş
    gruplara karşı ayrımcılık yapan ırkçı şeylere dönüştürebilir. Yorumlanabilirlik modellerdeki ön yargıları ortadan kaldırmaya
    yarayan kullanışlı bir araçtır. Kredi başvurularını otomatik olarak kabul etmek veya reddetmek üzere eğittiğiniz model geçmişte
    haklarından mahrum bırakılmış azınlıkları ayrıştırabilir. Amacınız zamanı geldiğinde parayı geri ödeyecek kişilere kredi
    vermektir. Bu durumda problemin tanımlanmasının eksikliği, yalnızca kredi temerrütlerini en aza indirmek
    istemeniz değil, aynı zamanda belirli demografik özellikler temelinde ayrımcılık yapmamak zorunda olmanız
    gerçeğinde yatmaktadır. Bu, problem tanımınızın bir parçası olan (düşük riskli ve uyumlu bir şekilde kredi verme)
    ek bir kısıtlamadır ve modelin optimize edildiği kayıp fonksiyonunun kapsamında değildir.
  </p>
  <p>
  Makinelerin ve algoritmaların hayatımıza entegre edilmesi, <strong>toplum tarafından kabul edilebilirliği</strong>
    arttırmak için yorumlanabilirliğe ihtiyaç duyar. İnsanlar nesnelere inançlar, arzular, niyetler vb. atfeder.
    Meşhur bir deneyde, Heider ve Simmel (1994)<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>
    katılımcılara bir çemberin kapıyı açıp odaya (bir üçgen) girdiği bir video gösterdiler. Katılımcılar şekillerin
    hareketlerini sanki insanlardan bahsediyormuş gibi niyetler, duygular hatta kişilik özellikleri atfederek
    açıkladılar. Robotlar buna iyi bir örnek, benim Doge adını verdiğim elektrikli süpürgem gibi. Doge sıkıştığında
    şöyle düşünüyorum: "Doge temizliğe devam etmek istiyor, fakat benden yardım istiyor çünkü sıkıştı." Sonra, Doge
    temizliği bitirip odada şarj istasyonunu ararken "Doge yeniden şarj olmayı istiyor ve istasyonunu arıyor." diye 
    düşünüyorum. Aynı zamanda kişilik özellikleri de atfediyorum: "Doge biraz aptal, ama sevimli bir şekilde." Bunlar
    Doge'yi izlerken, özellikle temizliği sırasında bir bitkiyi devirdiğinde aklıma gelen düşünceler. Tahminlerini
    açıklayan bir makine ya da algoritma daha kabullenilebilir olacaktır. <a href="explanation.html#explanation">
    Açıklamalarla ilgili bölümde</a> açıklamanın sosyal bir süreç olduğundan bahsettim.</p>

 <p>
  Açıklamalar <strong>sosyal etkileşimleri kontrol etmeye</strong> yarar. Bir şeyi herkesçe kabul edilmiş
   bir şekilde anlamlandırarak açıklayan kimse açıklamayı yaptığı kişinin
   hareketlerini, duygularını ve inançlarını etkiler. Bir makinenin bizle etkileşime geçmesi için
   duygularımızı ve inançlarımızı şekillendirmesi gerekebilir. Makinelerin bizi "ikna etmeleri" gerekir ki
   hedeflerine ulaşabilsinler. Davranışlarını belli bir seviyede açıklamasa elektrikli süpürgemi
   tam anlamıyla kabul etmezdim. Elektrikli süpürge örneğin bir kazanın (banyo halısına takılmak gibi)
   ortak bir açıklamasını hiçbir yorum yapmadan çalışmayı durdurmak yerine sıkıştığını anlatarak yapar.
   İlginç bir şekilde, açıklamayı yapan makinenin amacıyla (güven oluşturmak)
   açıklamayı dinleyenin amacı (tahmini veya davranışı anlamak) arasında bir uyuşmazlık olabilir.
   Doge'nin sıkışmasının tam bir açıklaması neredeyse bitmiş bir pil, çalışmayan bir tekerlek ve robotu
   engel olmasına rağmen sürekli aynı yanlış yere götüren bir bug olabilir. Bu üç neden (ve birkaç tanesi daha)
   robotun sıkışmasına sebep olmasına rağmen robot sadece yolda bir engel olduğunu açıklıyor, ki bu
   onun davranışına güvenmem ve kazanın ortak bir açıklamasını yapmam için yeterli. Bu arada, Doge tekrar
   banyoda sıkıştı. O temizliğe başlamadan önce halıları kaldırmalıyım.
  </p>
  
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:doge-stuck"></span>
<img src="images/doge-stuck.jpg" alt="Doge, our vacuum cleaner, got stuck. As an explanation for the accident, Doge told us that it needs to be on an even surface." width="\textwidth" />
<p class="caption">
FIGURE 3.2: Elektrikli süpürgemiz Doge sıkıştı. Kazayı düz zemin gerekliliğiyle açıklıyor.
</p>
</div>
  
  <p>
  Makine öğrenmesi modellerini <strong>tamir etmenin ve denetlemenin</strong> tek yolu onları yorumlayabilmektir. Film tavsiyesi gibi
    düşük riskli durumlarda bile yorumlayabilme kapasitesi, ürünün dağıtımı sonrasında olduğu gibi araştırma ve üretme sürecinde de büyük önem taşır.
    Model hazırlanıp üründe kullanıldıktan sonra işler ters gidebilir. Modelin hatalı tahminlerinin yorumlanması sorunun nedenini anlamamızı sağlar. Çözüme
    giden yolu bu belirler. Eskimo köpeklerini ve kurtları sınıflandırırken bazı Eskimo köpeklerini kurt olarak sınıflandıran bir model hayal edin. Makine öğrenmesinde
    yorumlama metotlarını kullanarak hatalı sınıflandırmanın resimlerdeki karlar olduğunu görebilirsiniz. Sınıflandırma modeli resimdeki karları
    resmi "kurt" olarak sınıflandırmada bir nitelik olarak kullanmıştır, bu eğitim verisi içerisinde sınıflandırma yaparken anlamlı olsa da gerçek dünyada
    her zaman doğru değildir.</p>
<p>Eğer modeliniz kararlarını açıklayabiliyorsa, aşağıdaki özelliklerini kolayca test edebilirsiniz (Doshi-Velez ve Kim 2017):</p>
  <ul>
  <li>Adillik: Tahminlerin ön yargısız olması ve dolaylı veya direkt olarak azınlıkları ayırmaması.
    Modeliniz, eğer kararlarını açıklayabiliyorsa, kredi başvurusunu reddettiği kişiye neden kredi vermediğini açıklayabilir, ve böylece
    bir insan kararın demografik (örneğin ırksal) ön yargıya dayanıp dayanmadığını kontrol edebilir.</li>
  <li>Gizlilik: Verideki hassas bilgilerin güvende olması.</li>
    <li>Dayanıklılık: Girdideki küçük değişikliklerin çıktıda büyük değişikliklere sebep olmaması.</li>
    <li>Nedensellik: Sadece nedensel ilişkilerin seçilmesi.</li>
<li>Güvenilirlik: Kararlarını açıklayan bir sisteme güvenmek bir kara kutuya güvenmekten çok daha kolaydır.</li>
  </ul>
  <p><strong>Yorumlamaya ihtiyacımız olmayan durumlar:</strong></p>
<p>Aşağıdaki senaryolar yorumlanabilirliğe ihtiyacımız olmayan hatta onu istemeyeceğimiz durumları örnekliyor.</p>
  <p>
  Eğer modelin <strong>kayda değer bir etkisi yoksa</strong> yorumlanmasına ihtiyaç yoktur. Mike adında birisinin, Facebook verisini kullanarak
    arkadaşlarının bir sonraki tatillerde nereye gideceklerini tahmin etmek üzere bir yan proje üzerinde çalıştığını hayal edin. Mike'ın tek istediği
    arkadaşlarını üstünde çalışılmış tahminlerle şaşırtmak. Modelin yanlış çalışması küçük bir utanç dışında hiçbir probleme sebep olmaz, ya da Mike'ın modelini
    açıklayamaması dert değildir. Böyle bir durumda yorumlanabilirliğin yokluğu kabul edilebilirdir. Eğer Mike bu model etrafında bir iş kurmaya başlarsa durum
    değişir. Modelin yanlış çalışması para kaybettirebilir ya da ırksal ön yargıdan ötürü model bazı insanlar için kötü çalışabilir. Modelin etki alanı
    finansal ya da sosyal anlamda büyüdüğü an yorumlanabilirlik önemli hale gelir.</p>
  <p>
    Eğer eldeki <strong>problem iyice araştırılmışsa</strong> yorumlanabilirliğe ihtiyaç yoktur. Bazı durumlarda problem iyice araştırıldığından
    modelle ilgili yeterli pratik tecrübe birikmiş ve modelde karşılaşılabilecek problemler zaman içinde çözülmüştür. Buna iyi bir örnek mektup görüntülerini
    işleyip adresleri veren görsel karakter tanıma modelidir. Bu sistemle yıllarca tecrübe biriktirilmiştir ve çalışabildikleri gayet ortadadır. Eldeki problemle
    ilgili ek içgörülere artık pek gerek yoktur.
  </p>
 <p>
  Yorumlanabilirlik, kişilerin veya programların <strong>sistemi manipüle etmesine</strong> olanak sağlayabilir.
   Sistemi kandıran kullanıcı problemi, modelin üreticisinin ve kullanıcının hedefleri arasındaki uyumsuzluktan dolayı ortaya çıkar. Kredi puanı sistemi
   bu probleme açık çünkü modelin sahibi bankanın hedefi krediyi ödeyecek kişiye vermekken, kullanıcının hedefi banka ona kredi vermek istemese de alabilmek.
   Bu amaçlar arasındaki uyumsuzluk kullanıcıları sisteme oyun oynayarak kredi başvurularının kabulü olasılığını arttırmaya teşvik ediyor. Eğer başvuran kişi
   ikiden fazla kredi kartına sahip olmanın kredi puanını negatif etkilediğini biliyorsa, üçüncü kartını iptal eder ve krediyi aldıktan sonra tekrar üçüncü bir kart
   çıkartır. Sistemin gözünde puanı artsa da krediyi ödeme olasılığı değişmemiştir. Sistem ancak, eğer girdiler, nedensel bir nitelik için vekilse ama sonucun direkt
   bir nedeni değilse manipüle edilebilir. Eğer mümkünse vekil niteliklerden kaçınılmalıdır çünkü modelleri manipülasyona açık hale getirirler. Buna örnek olarak
   Google'ın grip salgınlarını tahmin etmek üzere geliştirdği Google Flu Trends gösterilebilir. Sistem Google aramalarının grip salgınlarıyla korelasyonuna odaklandı
   ve model kötü performans gösterdi. Arama dağılımı değişti ve sistem birçok salgını tahmin edemedi. Çünkü Google aramaları grip salgınlarının sebebi değildi. Kullanıcıların
   "yüksek ateş" gibi semptomları aratmaları ve grip salgınları arasındaki ilişki sadece korelasyondan ibaret. İdeal anlamda modeller manipüle edilmemek adına
   sadece nedensel nitelikler kullanırlar.</p>
<!--{pagebreak}-->
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Doshi-Velez, Finale, and Been Kim. “Towards a rigorous science of interpretable machine learning,” no. Ml: 1–13. <a href="http://arxiv.org/abs/1702.08608" class="uri">http://arxiv.org/abs/1702.08608</a> (2017).<a href="interpretability-importance.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Heider, Fritz, and Marianne Simmel. “An experimental study of apparent behavior.” The American Journal of Psychology 57 (2). JSTOR: 243–59. (1944).<a href="interpretability-importance.html#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="interpretability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="taxonomy-of-interpretability-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/manuscript/02-interpretability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["interpretable-ml.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
